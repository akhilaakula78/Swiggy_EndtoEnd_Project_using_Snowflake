# Swiggy End-to-End Data Engineering Project using Snowflake

This project simulates the data ecosystem of Swiggy â€” a major food aggregator â€” using a complete ELT data engineering pipeline. It covers everything from data loading and transformation in **Snowflake** to visualization using **Streamlit**.


## Architecture Overview

> End-to-End Flow: Raw CSV âœ Staging âœ Cleansing âœ Consumption Layer âœ KPIs âœ Dashboard

---

## âš™ï¸ Tech Stack

| Tool        | Purpose                             |
|-------------|-------------------------------------|
| Snowflake   | Cloud Data Warehouse                |
| Streamlit   | Interactive KPI Dashboard           |
| Python      | Scripting for automation            |
| CSV         | Simulated data input                |

---

## ğŸ—‚ï¸ Folder Structure

```
Swiggy_EndtoEnd_Project_using_Snowflake/
â”œâ”€â”€ SQL_Scripts/                          # SQL DDL/DML scripts for Snowflake
â”‚   â”œâ”€â”€ 01 Create DW, DB & Schema.sql
â”‚   â”œâ”€â”€ 02-13 Entity & Fact Table Scripts
â”‚   â””â”€â”€ 13 KPI Views.sql
â”‚
â”œâ”€â”€ Streamlit_App_Code_Python/
â”‚   â””â”€â”€ Swiggy_Revenue_Dashboard_Streamlit_Code.py  # Final KPI Dashboard
â”‚
â””â”€â”€ README.md
```

---

## ğŸ”„ Data Pipeline Steps

### 1ï¸âƒ£ Load Data into Snowflake
- Use **Snowsight** or SnowSQL `COPY INTO` commands
- Files: `customers.csv`, `orders.csv`, etc.

### 2ï¸âƒ£ Create and Stage Tables
- Scripts: `01 Create DW, DB & Schema.sql`, staging table DDLs

### 3ï¸âƒ£ Clean & Transform
- Scripts: `02-10` for all entities
- `11 Date Dim.sql` and `12 Order Fact.sql` handle dimensional modeling

### 4ï¸âƒ£ KPIs & Views
- Use `13 KPI Views.sql` for insights like revenue, order volume, avg. delivery time

### 5ï¸âƒ£ Dashboard
- `Swiggy_Revenue_Dashboard_Streamlit_Code.py` builds an interactive Streamlit app

---

## ğŸ“ˆ Sample KPIs

- ğŸ” Total Orders by Location
- ğŸ›µ Avg. Delivery Time by City
- ğŸ’° Revenue by Restaurant
- â­ Ratings and Customer Retention

---

## ğŸ’¡ Key Learnings

- Data modeling with Fact/Dim structure
- Snowflake staging using `$` file notation
- Running delta loads using `COPY INTO`
- Designing consumption layers and views
- Dashboarding using Python and Streamlit

---

## ğŸ“Œ Future Scope

- Add dbt transformation layer
- Integrate Airflow to automate stages
- Push data from APIs (e.g., Swiggy live data)
- Add CI/CD for SQL and dashboard code

